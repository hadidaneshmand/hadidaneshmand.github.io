<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Neural Networks: A Theory Lab</title>
    <style>
        body {
	    width: 70%;
	    float: center;
            font-family: Arial, sans-serif;
            padding: 0;
	    margin: 0 auto;
    	    text-align: center;
        }
        header {
            background-color: blue;
            color: white;
            padding: 10px 20px;
            text-align: center;
        }
        nav {
            background-color: #ADD8E6; /* Light blue */
            overflow: hidden;
        }
        nav a {
            float: left;
            display: block;
            color: white;
            text-align: center;
            padding: 14px 16px;
            text-decoration: none;
        }

	img {
  		width: 90%;
		align: center
	}

        nav a:hover {
            background-color: #87CEEB; /* Sky blue */
            color: black;
        }
        .container {
            padding: 20px;
        }
        h2 {
            color: #4682B4; /* Steel blue */
        }
        .lecture-notes {
            margin-top: 20px;
        }
        .lecture-notes ul {
            list-style-type: none;
            padding: 0;
        }
        .lecture-notes li {
            margin-bottom: 10px;
        }
        footer {
            background-color: #4CAF50;
            color: white;
            text-align: center;
            padding: 10px;
            position: fixed;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>
<body>
    <header>
        <h1>Neural Networks: A Theory Lab</h1>
        <p>Instructor: Hadi Daneshmand </p>
        <p>TA:  Oishee Bintey Hoque </p>
        <p>Contact: xay7teATvirginiaDOTedu</p>
    </header>
    <nav>
        <a href="#about">About</a>
        <a href="#schedule">Schedule and Notes</a>
        <a href="#bulletin">Bulletin Board</a>
    </nav>
    <div class="container", style="text-align: left;">
        <section id="about">
            <h2>About the Course</h2>
<p> <p>
    In this course, we will delve into the mechanisms of neural networks through a combination of experimental observations and theoretical analyses. Specifically, we will examine significant experimental findings that have shaped theoretical advancements in machine learning and present the theoretical frameworks that explain these observations. 
</p>
<p>
    The image below summarizes the topics we plan to cover. We will begin with the central topic and navigate between theory and observation as the course progresses. Starting with shallow neural networks with a single layer, we will advance to discussions on deep convolutional networks and transformers. 
<div class="container", style="text-align: center;"> <img class="center" src="https://github.com/hadidaneshmand/neural-nets/blob/main/images/conceptmap.png?raw=true" alt="roadmap"> </div> 
</p>
<p>
    <strong>Note:</strong> This course is not designed to enhance implementation skills but rather to introduce open-ended research questions in the understanding of neural networks.
</p>
<br>
</p>
<b> Requirements: </b> Students are expected to have a foundational understanding of linear algebra, statistics, probability theory, and calculus and can program in Python. While required materials will be reviewed during the course, these prerequisites are essential for successful participation and comprehension.  

 </p>
        </section>
        <section id="schedule">
            <h2>Course Schedule and Notes</h2>
            <p>
		<ul>
		<li> Introduction <a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%200%20Introduction.key">slides.key</a>, 
<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%200%20Introduction.pdf">slides.pdf</a>  
<a href="https://colab.research.google.com/drive/1i9coc5Wnp6ODQ1SsDzNWj46Eg6aLJHZl">code</a> </li> 
	        <li> Bridging random features, kernel methods and neural networks (<a href="https://hackmd.io/@hadidanesh/SJJYw3Lvke">lecture notes</a>,<a href="https://colab.research.google.com/drive/1M-nRBdhg1XJiV8sy4wMkUsfPJLKKSCB0#scrollTo=diCPqiTj5wB3">group activity</a>)</li>
<ul> 
	<li>  Kernel methods 
(<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%201%20Universal%20Features.key">slides.key</a>, 
<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%201%20Universal%20Features.pdf">slides.pdf,
<a href="https://colab.research.google.com/drive/1M-nRBdhg1XJiV8sy4wMkUsfPJLKKSCB0#scrollTo=diCPqiTj5wB3">in-class task with solution</a>,
<a href="https://hackmd.io/@hadidanesh/SJJYw3Lvke">lecture notes</a>)</li>

<li> Random features (<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%202%20Random%20Features.key">slides.key</a>,        
<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%202%20Random%20Features.pdf">slides.pdf,
<a href="https://colab.research.google.com/drive/1M-nRBdhg1XJiV8sy4wMkUsfPJLKKSCB0#scrollTo=diCPqiTj5wB3">in-class task with solution</a>,
<a href="https://hackmd.io/@hadidanesh/SJJYw3Lvke">lecture notes</a>) </li>
<li> Curse of dimensionality for random features
(<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%203%20Curse%20of%20Dimensionality.key">slides.key</a>, 
<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%203%20Curse%20of%20Dimensionality.pdf">slides.pdf</a>
,
<a href="https://hackmd.io/D_xMlINMQau_QhfYWnEVag">lecture notes</a>, 
<a href="https://colab.research.google.com/drive/1SzLEF2EEMhjAXZkx86GuRxIwSkeTKbvs">task</a>,
<a href="https://colab.research.google.com/drive/12tj2k3i00D924fwTqmxvzMQ0JKcZgfc2">solution</a>,
<a href="https://www.cs.cmu.edu/afs/cs/academic/class/15750-s17/ScribeNotes/lecture11.pdf">reference</a>)</li> 
<li><a> Neural networks: Breaking curse of dimensionality </a> 
(<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%204%20Neurons%20as%20particles.key">slides.key</a>,
<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%204%20Neurons%20as%20particles.pdf">slides.pdf</a>
, 
<a href="https://colab.research.google.com/drive/1M-nRBdhg1XJiV8sy4wMkUsfPJLKKSCB0">task</a>,
<a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">reference</a>)

  </li>  
</ul> 
    		<li>Optimizatio: bridging mathematical programming and language models. </li>
<ul> 
<li> Curse of dimensionality and gradient descent   
(<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%205%20Gradient%20Descent.key">slides.key</a>,
<a href="https://github.com/hadidaneshmand/hadidaneshmand.github.io/raw/refs/heads/main/neural-nets/slides/Lecture%205%20Gradient%20Descent.pdf">slides.pdf</a>
,
<a href="https://colab.research.google.com/drive/14YN7jranjtwfVP4v4g4Is6-aPlXoWyZa?usp=sharing">task with solution</a>,reference: Ch1 of Introductory Lectures on Convex Optimization by by Yurii Nesterov) </li> 
</ul>  
<li> </li>   
		</ul>
	    </p>
        </section>
        <section id="bulletin" class="lecture-notes">
            <h2>Bulletin Board</h2>
            <ul>
		<li> >  <b> HW1 is <a href="https://hackmd.io/jB_FSABlQEKuQZrbSsp-pg?view">available</a> (deadline:Feb20)</b> </li> 
		<li><a> > Thank you so much Po-Wei Chen for <a href="https://hackmd.io/D_xMlINMQau_QhfYWnEVag"> the lecture note on Curse of dimensionality.</a> 
		<li><a> > Random feature lecture note is <a href="https://hackmd.io/@hadidanesh/SJJYw3Lvke">available</a></a></li> 
		<li><a> > Kernel methods lecture note is <a href="https://hackmd.io/@hadidanesh/SJJYw3Lvke">available</a>  </li></a>
		<li><a> >  Kernel methods slides are uploaded </li> </a> 
		<li><a> >  Introduction slides are uploaded </a> </li>
		<li><a> > <b> Please bring your laptops to the classroom</b></a></li>
                <li><a> > Slides on random features are uploaded</a></li>
                <!-- Add more links as needed -->
            </ul>
        </section>
    </div>

    
        &copy; 2024 Hadi Daneshmand. All rights reserved.
   
</body>
</html>
